{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, bs4\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "DELAY_BETWEEN_PAGES = 2\n",
    "BASE_URL = 'https://www.bildung.berlin.de/Schulverzeichnis/SchulListe.aspx'\n",
    "BASE_PORTRAIT = 'https://www.bildung.berlin.de/Schulverzeichnis/Schulportrait.aspx'\n",
    "\n",
    "# 2022 https://www.bildung.berlin.de/Schulverzeichnis/SchulListe.aspx?BezNr=06\n",
    "# 2022 https://www.bildung.berlin.de/Schulverzeichnis/Schulportrait.aspx?IDSchulzweig=%2023251\n",
    "\n",
    "bezirk_dict = {'01': 'Mitte',\n",
    "                '02': 'Friedrichshain-Kreuzberg',\n",
    "                '03': 'Pankow',\n",
    "                '04': 'Charlottenburg-Wilmersdorf',\n",
    "                '05': 'Spandau',\n",
    "                '06': 'Steglitz-Zehlendorf',\n",
    "                '07': 'Tempelhof-Schöneberg',\n",
    "                '08': 'Neukölln',\n",
    "                '09': 'Treptow-Köpenick',\n",
    "                '10': 'Marzahn-Hellersdorf',\n",
    "                '11': 'Lichtenberg',\n",
    "                '12': 'Reinickendorf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bezirk_page(bezirk_nummer):\n",
    "    bezirk_url = BASE_URL + '?BezNr=' + bezirk_nummer\n",
    "    res = requests.get(bezirk_url)\n",
    "    res.raise_for_status()\n",
    "    return bs4.BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "def get_school_ids(soup_area):\n",
    "    school_links = soup_area.select('a')\n",
    "    return [str(x).split('=')[2][1:6] for x in school_links if 'IDSchulzweig' in str(x)]\n",
    "\n",
    "def get_school_info(school_id):\n",
    "        result = dict()\n",
    "        school_url = BASE_PORTRAIT + '?IDSchulzweig=%20' + school_id\n",
    "        res_school = requests.get(school_url)\n",
    "        res_school.raise_for_status()\n",
    "        soup_school = bs4.BeautifulSoup(res_school.text, 'html.parser')\n",
    "        temp = soup_school.find('div', {'id': 'divAllgemein'})\n",
    "        result['schulname'] = temp.find('span', {'id':'ContentPlaceHolderMenuListe_lblSchulname'}).getText().strip()\n",
    "        result['schulart'] = temp.find('span', {'id':'ContentPlaceHolderMenuListe_lblSchulart'}).getText().strip()\n",
    "        result['strasse'] = temp.find('span', {'id':'ContentPlaceHolderMenuListe_lblStrasse'}).getText().strip()\n",
    "        result['ort'] = temp.find('span', {'id':'ContentPlaceHolderMenuListe_lblOrt'}).getText().strip()\n",
    "        result['tel'] = temp.find('span', {'id':'ContentPlaceHolderMenuListe_lblTelefon'}).getText().strip()\n",
    "        result['email'] = temp.find('a', {'id':'ContentPlaceHolderMenuListe_HLinkEMail'}).getText().strip()\n",
    "        result['leitung'] = temp.find('span', {'id':'ContentPlaceHolderMenuListe_lblLeitung'}).getText().strip()\n",
    "        return result\n",
    "\n",
    "def clean_up_data(school_info):\n",
    "    result = pd.DataFrame(school_info)\n",
    "    result.email = result.email.str.replace('%09', '')\n",
    "    result.email = result.email.str.replace(' ', '')\n",
    "    result.email = result.email.str.replace('%20', '')\n",
    "    try:\n",
    "        result[['email1', 'email2']] = result.email.str.split(';', expand=True)\n",
    "    except ValueError:\n",
    "        result['email1'] = result['email']\n",
    "        result['email2'] = None\n",
    "    result = result[result.email.str.contains('@')]\n",
    "    result = result[~result.email1.duplicated()]\n",
    "    COLS = ['schulart','schulname','strasse','ort', 'tel','email1', 'leitung']\n",
    "\n",
    "    return result[COLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping : Reinickendorf\n",
      "25\n",
      "50\n",
      "75\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for bezirk_nummer, bezirk_name in bezirk_dict.items():\n",
    "    # if bezirk_nummer != '01': continue #uncomment if only one Bezirk is required\n",
    "    print('Scraping :', bezirk_name)\n",
    "    soup_area = get_bezirk_page(bezirk_nummer)\n",
    "    school_ids = get_school_ids(soup_area)\n",
    "    school_info = list()\n",
    "    n = 1\n",
    "    for school_id in school_ids:\n",
    "        school_info.append(get_school_info(school_id))\n",
    "        time.sleep(DELAY_BETWEEN_PAGES)\n",
    "        if n%25==0: print(n)\n",
    "        n+=1\n",
    "    result = clean_up_data(school_info)\n",
    "    result.to_csv(bezirk_nummer + '_' + bezirk_name + '.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "interpreter": {
   "hash": "b0810a52c1f7e1ee424e2c89aaab56c9fabbc4ec69d6049540fb0ebe12249069"
  },
  "kernelspec": {
   "display_name": "Python 3.6.0 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "orig_nbformat": 2,
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
